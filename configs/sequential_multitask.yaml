# Sequential Multi-Task Training Configuration
# Trains sequence_instructed -> inferred sequentially

trainer_type: sequential
random_seed: 42

tasks:
  - task_type: sequence_instructed
    num_steps: 1000
    task:
      dt: 10.0
      input_noise_std: 0.1
      inter_trial_interval: 1000.0
      reward_duration: 500.0
      w_m: 0.1
      trials_per_sequence: 40

  - task_type: inferred
    num_steps: 2000
    task:
      dt: 10.0
      pulse_width: 50.0
      decision_threshold: 850.0
      delta_t_min: 530.0
      delta_t_max: 1170.0
      fixation_delay_min: 400.0
      fixation_delay_max: 900.0
      rule_report_period: 700.0
      response_period: 700.0
      grace_period: 400.0
      input_noise_std: 0.1
      inter_trial_interval: 1000.0
      reward_duration: 500.0
      w_m: 0.1
      block_min: 10
      block_mean: 6
      trials_per_sequence: 40

model:
  input_size: 5
  hidden_size: 256
  output_size: 2
  tau: 100.0
  dt: 10.0
  activation: elu
  noise_std: 0.1

training:
  learning_rate: 0.0003
  batch_size: 64
  log_interval: 20
  num_eval_samples: 32
  checkpoint_interval: 500
  log_dir: logs/sequential_multitask
  reset_optimizer_between_tasks: true  # Maintain momentum across tasks
