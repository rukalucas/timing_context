# instructed (start_from) -> transition (rule_cue_prob 0.9->0.0 gradually)

trainer_type: sequential
random_seed: 42

wandb:
  project: "timing_context"
  offline: false  # Set to true for offline mode

tasks:
  - task_type: instructed
    num_steps: 0 #for logging
    eval: true
    task:
      trials_per_sequence: 40

  - task_type: inferred
    num_steps: 0 #for logging
    eval: true
    task:
      trials_per_sequence: 40

  - task_type: transition
    num_steps: 4000
    eval: false
    task:
      rule_cue_prob: 0.9  # Starting value (will be scheduled)
      trials_per_sequence: 40
    schedule:
      param_name: rule_cue_prob
      start_value: 0.9
      end_value: 0.0

model:
  hidden_size: 256
  tau: 100.0
  activation: elu

training:
  learning_rate: 1e-4
  batch_size: 128
  total_steps: 4000
  log_interval: 20
  num_eval_samples: 128
  checkpoint_interval: 500
  log_dir: logs/transition
  reset_optimizer_between_tasks: true
  optimizer_type: adam
  # weight_decay: 1e-4 # for adamw
  clip_grad_norm: 1.0 # clip recurrent weight grad

start_from: logs/instructed/checkpoint_final.pt